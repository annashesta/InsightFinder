# web_app.py

import streamlit as st
import pandas as pd
from core.pipeline import analyze_dataset
import os
import glob
import base64
import io
import zipfile
from core.logger import get_logger

logger = get_logger(__name__, "orchestrator.log")

def clear_tmp_directory():
    """–û—á–∏—â–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é tmp"""
    try:
        for file in os.listdir("tmp"):
            file_path = os.path.join("tmp", file)
            try:
                if os.path.isfile(file_path):
                    os.unlink(file_path)
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {file_path}: {e}")
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ tmp: {e}")


st.title("InsightFinder ‚Äî AI –∞–≥–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö")

st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ API")
st.write("–í–∞–∂–Ω–æ: –Ω–µ–≤–µ—Ä–Ω—ã–π –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π –∫–ª—é—á –ø—Ä–∏–≤–µ–¥—ë—Ç –∫ –æ—à–∏–±–∫–∞–º.")
with st.form("env_form"):
    api_key = st.text_input("–í–≤–µ–¥–∏—Ç–µ OPENAI_API_KEY", type="password")
    base_url = st.text_input("–í–≤–µ–¥–∏—Ç–µ OPENAI_BASE_URL", value="https://openai-hub.neuraldeep.tech")

    submitted = st.form_submit_button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")

    if submitted:
        with open(".env", "w", encoding="utf-8") as f:
            f.write(f"OPENAI_API_KEY={api_key}\n")
            f.write(f"OPENAI_BASE_URL={base_url}\n")
        
        st.success("‚úÖ –§–∞–π–ª .env —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!")
        logger.info("‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (API) –∏–∑ —Ñ–æ—Ä–º—ã.")

        # —á—Ç–æ–±—ã —Å—Ä–∞–∑—É –ø–æ–¥—Ö–≤–∞—Ç–∏—Ç—å –≤ —Ç–µ–∫—É—â–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏
        os.environ["OPENAI_API_KEY"] = api_key
        os.environ["OPENAI_BASE_URL"] = base_url



file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª", type=["csv"])

st.write("–í–∞–∂–Ω–æ: –Ω–µ –ø—ã—Ç–∞–π—Ç–µ—Å—å –∏–∑–º–µ–Ω–∏—Ç—å —Ñ–∞–π–ª –∏–ª–∏ —Ç–∞—Ä–≥–µ—Ç, –ø–æ–∫–∞ –∏–¥—ë—Ç —Ç–µ–∫—É—â–∏–π –∞–Ω–∞–ª–∏–∑. –≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –æ—à–∏–±–∫–∞–º.")
if file:
    logger.info("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å.")
    df = pd.read_csv(file)
    st.write("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä:", df.head())

    target_col = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∞—Ä–≥–µ—Ç", df.columns)
    
    st.write("–í–∞–∂–Ω–æ: –Ω–µ –ø—ã—Ç–∞–π—Ç–µ—Å—å –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑, –ø–æ–∫–∞ –∏–¥—ë—Ç —Ç–µ–∫—É—â–∏–π. –≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –æ—à–∏–±–∫–∞–º.")
    if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑"):
        os.makedirs("tmp", exist_ok=True)
        tmp_path = os.path.join("tmp", file.name)

        with open(tmp_path, "wb") as f:
            f.write(file.getbuffer())

        # —Å–æ–∑–¥–∞—ë–º "–ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä" –¥–ª—è —Å—Ç–∞—Ç—É—Å–∞
        status_placeholder = st.empty()
        status_placeholder.info("‚è≥ –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—É—â–µ–Ω...")

        try:
            report_path, history, report = analyze_dataset(tmp_path, target_col)

            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–µ—Å—Å–∏—é
            st.session_state["report"] = report
            st.session_state["report_path"] = report_path
            st.session_state["history"] = history

        finally:
            status_placeholder.empty()
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            clear_tmp_directory()
            logger.info("‚úÖ –í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è tmp –æ—á–∏—â–µ–Ω–∞.")



# –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—á–µ—Ç –∏ –∫–Ω–æ–ø–∫—É —Å–∫–∞—á–∏–≤–∞–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
if "report" in st.session_state:
    st.subheader("üìë –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç")
    st.markdown(st.session_state["report"], unsafe_allow_html=True)

    with open(st.session_state["report_path"], "r", encoding="utf-8") as f:
        st.download_button(
            label="üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç (.md)",
            data=f.read(),
            file_name=os.path.basename(st.session_state["report_path"]),
            mime="text/markdown"
        )
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    if "history" in st.session_state:
        image_paths = []
    
        # –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç DistributionVisualizer –∏ InsightDrivenVisualizer
        for step in st.session_state["history"]:
            if step["tool_name"] == "DistributionVisualizer" and step["status"] == "success":
                visualizations = step["details"].get("visualizations", {})
                if visualizations:
                    st.subheader("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π")
                    for feature, viz in visualizations.items():
                        st.markdown(f"**{feature}** ‚Äî {viz['description']}")
                        img_bytes = base64.b64decode(viz["image_base64"])
                    
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è ZIP
                        temp_path = os.path.join("tmp", f"distribution_{feature}.png")
                        with open(temp_path, 'wb') as f:
                            f.write(img_bytes)
                        image_paths.append(temp_path)
                    
                        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                        st.image(img_bytes, use_container_width=True)

        for step in st.session_state["history"]:
            if step["tool_name"] == "InsightDrivenVisualizer" and step["status"] == "success":
                saved_plots = step["details"].get("saved_plots", {})
                if saved_plots:
                    st.subheader("üí° –ò–Ω—Å–∞–π—Ç-–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
                
                    for feature, plot_info in saved_plots.items():
                        st.markdown(f"### {feature}")
                        st.markdown(plot_info.get("description", ""))
                    
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≥—Ä–∞—Ñ–∏–∫–æ–≤
                        for plot_type, path in plot_info.items():
                            if plot_type != "description":  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª–µ description
                                if isinstance(path, str) and os.path.exists(path):
                                    image_paths.append(path)
                                    with open(path, 'rb') as img_file:
                                        image_bytes = img_file.read()
                                        st.image(image_bytes, use_container_width=True)

    # –°–æ–∑–¥–∞–µ–º ZIP-–∞—Ä—Ö–∏–≤ —Å–æ –≤—Å–µ–º–∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
        if image_paths:
            st.markdown(f"### üì• –í—Å–µ–≥–æ –≥—Ä–∞—Ñ–∏–∫–æ–≤: {len(image_paths)}")
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, 'w') as zip_file:
                for img_path in image_paths:
                    filename = os.path.basename(img_path)
                    zip_file.write(img_path, filename)
        
            zip_buffer.seek(0)
            st.download_button(
                label="üì• –°–∫–∞—á–∞—Ç—å –≤—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ (.zip)",
                data=zip_buffer,
                file_name="visualizations.zip",
                mime="application/zip"
            )

    st.subheader("üìú –õ–æ–≥–∏ –∞–≥–µ–Ω—Ç–æ–≤")

    log_files = glob.glob("logs/*.log")

    if log_files:
        for log_file in log_files:
            with open(log_file, "r", encoding="utf-8") as f:
                st.download_button(
                    label=f"üì• –°–∫–∞—á–∞—Ç—å {os.path.basename(log_file)}",
                    data=f.read(),
                    file_name=os.path.basename(log_file),
                    mime="text/plain"
                )
    logger.info("‚úÖ –í—ã–≤–µ–¥–µ–Ω —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç")