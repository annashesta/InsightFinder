# core/orchestrator.py
from agents.analyst_agent import create_analyst_agent
from agents.executor_agent import ExecutorAgent
from agents.tools_wrapper import set_current_data, ALL_TOOLS
from langchain_core.messages import HumanMessage
import pandas as pd
import json
from core.logger import get_logger
from agents.summarizer_agent import generate_summary
from core.utils import make_serializable

logger = get_logger(__name__, "orchestrator.log")


def run_simple_orchestration(
    df: pd.DataFrame, target_column: str, filename: str = "data.csv"
) -> tuple[list[dict], str]:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä: —Ä–∞–±–æ—Ç–∞–µ—Ç —Å JsonOutputParser.
    """
    logger.info("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤")
    set_current_data(df, target_column)

    analyst = create_analyst_agent(ALL_TOOLS)
    executor = ExecutorAgent(ALL_TOOLS)
    logger.info("–ê–≥–µ–Ω—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")

    history = []
    insights = []

    step_num = 1
    while True:
        logger.info(f"–®–∞–≥ {step_num}: –∑–∞–ø—Ä–æ—Å –∫ Analyst Agent")

        if not history:
            question = "–ù–∞—á–Ω–∏ –∞–Ω–∞–ª–∏–∑ —Å PrimaryFeatureFinder."
        else:
            serializable_history = make_serializable(history)
            history_json = json.dumps(serializable_history, ensure_ascii=False, indent=2)
            question = (
                "–£—á–∏—Ç—ã–≤–∞–π –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n\n"
                f"--- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —à–∞–≥–æ–≤ ---\n{history_json}"
            )

        try:
            # ‚ùå response = analyst.invoke(...).content
            # ‚úÖ response ‚Äî —ç—Ç–æ dict, –Ω–µ AIMessage
            response = analyst.invoke({
                "messages": [HumanMessage(content=question)],
                "agent_scratchpad": []
            })
            logger.info(f"‚úÖ Analyst –≤–µ—Ä–Ω—É–ª: {response}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ Analyst: {e}")
            break

        # === –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç ===
        try:
            # response ‚Äî —ç—Ç–æ dict, –∞ –Ω–µ —Å—Ç—Ä–æ–∫–∞
            next_step = response["next_step"]
            tool_name = next_step["tool"]
            logger.info(f"üîç Analyst –≤—ã–±—Ä–∞–ª: {tool_name}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è next_step: {e}")
            break

        # === STOP ===
        if tool_name.upper() == "STOP":
            logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω: {next_step.get('reason', '–û–∫–æ–Ω—á–∞–Ω–∏–µ')}")
            break

        # === –ó–∞–ø—É—Å–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ ===
        try:
            result = executor.run_one_step(tool_name, df=df, target_column=target_column)
            logger.info(f"üöÄ Executor –≤—ã–ø–æ–ª–Ω–∏–ª {tool_name}: —Å—Ç–∞—Ç—É—Å={result['status']}")
            if result["status"] == "error":
                logger.error(f"‚ùå –û—à–∏–±–∫–∞: {result['error_message']}")
        except Exception as e:
            logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ {tool_name}: {e}")
            result = {
                "tool_name": tool_name,
                "status": "error",
                "summary": "",
                "details": {},
                "error_message": str(e),
            }

        # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ===
        history.append({
            "tool_name": result["tool_name"],
            "status": result["status"],
            "summary": result["summary"],
            "details": make_serializable(result["details"]),
        })

        if result["status"] == "success":
            insights.append(result["summary"])

        step_num += 1

    # === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ ===
    logger.info("üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞")
    final_report = generate_summary(insights=insights, tool_results=history, filename=filename)

    return history, final_report