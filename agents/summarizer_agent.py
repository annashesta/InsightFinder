# agents/summarizer_agent.py
import os
from typing import List, Dict, Any, Optional

from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

from core.logger import get_logger

load_dotenv()
logger = get_logger(__name__, "summarizer.log")


def _format_categorical_details(result: Optional[Dict[str, Any]]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
    if not result or result["status"] != "success":
        return ""
    
    details = result.get("details", {})
    significant_features = details.get("significant_features", {})
    
    if not significant_features:
        return ""
    
    lines = ["\n**–ó–Ω–∞—á–∏–º—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:**"]
    for feature, stats in significant_features.items():
        p_val = stats.get('p_value', 'N/A')
        chi2 = stats.get('chi2', 'N/A')
        lines.append(f"- {feature}: p-value={p_val:.2e}, chi2={chi2:.2f}")
    
    return "\n".join(lines)


def _format_correlation_details(result: Optional[Dict[str, Any]]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞."""
    if not result or result["status"] != "success":
        return ""
    
    details = result.get("details", {})
    top_pos = details.get("top_positive", {})
    top_neg = details.get("top_negative", {})
    
    lines = []
    if top_pos:
        lines.append("\n**–¢–æ–ø –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π:**")
        for feature, corr in top_pos.items():
            lines.append(f"- {feature}: {corr:.3f}")
    
    if top_neg:
        lines.append("\n**–¢–æ–ø –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π:**")
        for feature, corr in top_neg.items():
            lines.append(f"- {feature}: {corr:.3f}")
    
    return "\n".join(lines)


def _format_stats_details(result: Optional[Dict[str, Any]]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫."""
    if not result or result["status"] != "success":
        return ""
    
    details = result.get("details", {})
    diffs = details.get("significant_differences", [])
    
    if not diffs:
        return ""
    
    lines = ["\n**–ó–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –ø–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞–º:**"]
    for diff in diffs:
        feature_stat = diff.get("feature_stat", "N/A")
        val_0 = diff.get("group_0", "N/A")
        val_1 = diff.get("group_1", "N/A")
        rel_diff = diff.get("relative_difference", "N/A")
        rel_diff_pct = rel_diff * 100 if rel_diff != "N/A" else "N/A"
        lines.append(f"- {feature_stat}: –≥—Ä—É–ø–ø–∞ 0={val_0:.3f}, –≥—Ä—É–ø–ø–∞ 1={val_1:.3f}, —Ä–∞–∑–Ω–∏—Ü–∞={rel_diff_pct:.1f}%")
    
    return "\n".join(lines)


def _format_model_details(result: Optional[Dict[str, Any]]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
    if not result or result["status"] != "success":
        return ""
    
    details = result.get("details", {})
    importances = details.get("feature_importances", {})
    
    if not importances:
        return ""
    
    lines = ["\n**–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ Random Forest:**"]
    for feature, importance in importances.items():
        lines.append(f"- {feature}: {importance:.4f}")
    
    return "\n".join(lines)


def _format_visualization_details(result: Optional[Dict[str, Any]]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –æ—Ç—á—ë—Ç–∞."""
    if not result or result["status"] != "success":
        return ""
    
    details = result.get("details", {})
    visualizations = details.get("visualizations", {})
    
    if not visualizations:
        return ""
    
    lines = ["\n**–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π:**"]
    for feature, viz_data in visualizations.items():
        image_base64 = viz_data.get("image_base64", "")
        description = viz_data.get("description", "")
        lines.append(f"\n### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {feature}")
        lines.append(f"*{description}*")
        lines.append(f"![{feature}](data:image/png;base64,{image_base64})")
    
    return "\n".join(lines)


def _format_outlier_details(result: Optional[Dict[str, Any]]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤."""
    if not result or result["status"] != "success":
        return ""
    
    details = result.get("details", {})
    outliers = details.get("outliers", {})
    
    if not outliers:
        return ""
    
    lines = ["\n**–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –≤—ã–±—Ä–æ—Å—ã:**"]
    lines.append("| –ü—Ä–∏–∑–Ω–∞–∫ | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤ | –ü—Ä–æ—Ü–µ–Ω—Ç | –ú–µ—Ç–æ–¥ |")
    lines.append("|---------|-------------------|---------|-------|")
    for feature, stats in outliers.items():
        count = stats.get('count', 'N/A')
        percentage = stats.get('percentage', 'N/A')
        method = stats.get('method', 'N/A')
        lines.append(f"| {feature} | {count} | {percentage:.2f}% | {method} |")
    
    return "\n".join(lines)


def _format_interaction_details(result: Optional[Dict[str, Any]]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π."""
    if not result or result["status"] != "success":
        return ""
    
    details = result.get("details", {})
    interactions = details.get("interactions", [])
    
    if not interactions:
        return ""
    
    lines = ["\n**–ê–Ω–∞–ª–∏–∑ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π:**"]
    lines.append("| –ü—Ä–∏–∑–Ω–∞–∫ | –¢–∏–ø | –ó–Ω–∞—á–µ–Ω–∏–µ | –ú–µ—Ç—Ä–∏–∫–∞ |")
    lines.append("|---------|-----|----------|---------|")
    for interaction in interactions:
        feature = interaction.get('feature', 'N/A')
        type_ = interaction.get('type', 'N/A')
        value = interaction.get('value', 'N/A')
        metric = interaction.get('metric', 'N/A')
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏ —Ç–∏–ø–∞
        if metric == "p_value":
            try:
                # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                p_val = float(value)
                value_str = f"p={p_val:.2e}"
            except (ValueError, TypeError):
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                value_str = f"p={value}"
                
            chi2 = interaction.get('chi2')
            if chi2 is not None:
                try:
                    chi2_val = float(chi2)
                    value_str += f", œá¬≤={chi2_val:.2f}"
                except (ValueError, TypeError):
                    value_str += f", œá¬≤={chi2}"
        else:
            # –î–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –∏ –¥—Ä—É–≥–∏—Ö –º–µ—Ç—Ä–∏–∫
            try:
                # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                corr_val = float(value)
                value_str = f"{corr_val:.3f}"
            except (ValueError, TypeError):
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                value_str = f"{value}"
            
        lines.append(f"| {feature} | {type_} | {value_str} | {metric} |")
    
    return "\n".join(lines)



SUMMARIZER_PROMPT = """
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏—Ç–∏–∫–µ. –ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –æ—Ç—á—ë—Ç.
–¢—ã –ù–ï –º–æ–∂–µ—à—å –≤—ã–¥—É–º—ã–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ. –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî –Ω–∞–ø–∏—à–∏ "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö".

–¶–µ–ª—å: –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: ¬´–ö–∞–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è –Ω–∞–∏–±–æ–ª–µ–µ —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç –≥—Ä—É–ø–ø—É 1 –æ—Ç –≥—Ä—É–ø–ø—ã 0?¬ª

–§–æ—Ä–º–∞—Ç –æ—Ç—á—ë—Ç–∞:
# –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á—ë—Ç –¥–ª—è —Ñ–∞–π–ª–∞ {filename}

## –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã
{insights_list}

## –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
### 1. –ü–æ–∏—Å–∫ –≥–ª–∞–≤–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
{primary_feature_summary}

### 2. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
{correlation_summary}
{correlation_details}

### 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
{descriptive_stats_summary}
{stats_details}

### 4. –ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
{categorical_analysis_summary}
{categorical_details}

### 5. –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
{visualization_summary}
{visualization_details}

### 6. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤
{outlier_summary}
{outlier_details}

### 7. –ê–Ω–∞–ª–∏–∑ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
{interaction_summary}
{interaction_details}

### 8. –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –ø–æ–ª–Ω–æ–π –º–æ–¥–µ–ª–∏
{full_model_summary}
{model_details}

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ–±—â–∏–π –≤—ã–≤–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–¥–µ–ª–æ–≤.
–û–±—ä—è—Å–Ω–∏, –∫–∞–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è –Ω–∞–∏–±–æ–ª–µ–µ —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç –≥—Ä—É–ø–ø—É 1 –æ—Ç –≥—Ä—É–ø–ø—ã 0.
–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –Ω–∞–ø–∏—à–∏ "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö".
"""


def generate_summary(
    insights: List[str], 
    tool_results: List[Dict[str, Any]], 
    filename: str = "unknown.csv"
) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á—ë—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤."""
    logger.info(f"üìù Summarizer Agent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Ñ–∞–π–ª–∞ {filename}")

    llm = ChatOpenAI(
        model="qwen2.5-32b-instruct",
        api_key=os.getenv("OPENAI_API_KEY"),
        base_url=os.getenv("OPENAI_BASE_URL"),
        temperature=0.3
    )

    results_map = {res["tool_name"]: res for res in tool_results}

    def get_summary(name: str) -> str:
        res = results_map.get(name)
        return res["summary"] if res and res["status"] == "success" else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –¥–µ—Ç–∞–ª–µ–π
    correlation_result = results_map.get("CorrelationAnalysis")
    stats_result = results_map.get("DescriptiveStatsComparator")
    categorical_result = results_map.get("CategoricalFeatureAnalysis")
    model_result = results_map.get("FullModelFeatureImportance")
    visualization_result = results_map.get("DistributionVisualizer")
    outlier_result = results_map.get("OutlierDetector")
    interaction_result = results_map.get("InteractionAnalyzer")

    insights_list = "\n".join([f"- {s}" for s in insights]) if insights else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

    prompt = ChatPromptTemplate.from_template(SUMMARIZER_PROMPT)
    chain = prompt | llm

    response = chain.invoke({
        "filename": filename,
        "insights_list": insights_list,
        "primary_feature_summary": get_summary("PrimaryFeatureFinder"),
        "correlation_summary": get_summary("CorrelationAnalysis"),
        "correlation_details": _format_correlation_details(correlation_result),
        "descriptive_stats_summary": get_summary("DescriptiveStatsComparator"),
        "stats_details": _format_stats_details(stats_result),
        "categorical_analysis_summary": get_summary("CategoricalFeatureAnalysis"),
        "categorical_details": _format_categorical_details(categorical_result),
        "visualization_summary": get_summary("DistributionVisualizer"),
        "visualization_details": _format_visualization_details(visualization_result),
        "outlier_summary": get_summary("OutlierDetector"),
        "outlier_details": _format_outlier_details(outlier_result),
        "interaction_summary": get_summary("InteractionAnalyzer"),
        "interaction_details": _format_interaction_details(interaction_result),
        "full_model_summary": get_summary("FullModelFeatureImportance"),
        "model_details": _format_model_details(model_result),
    })

    return response.content
